import json
import requests
import re
import yaml
import logging
import mysql.connector
from libs import chat

# Setup logging
logging.basicConfig(filename='cvebot-alert.log', level=logging.ERROR, 
                    format='%(asctime)s %(levelname)s:%(message)s')

def load_config():
    try:
        with open("config.yaml", "r") as config_file:
            return yaml.safe_load(config_file)
    except Exception as e:
        logging.error(f"Error loading config: {e}")
        return None

def connect_db(config):
    try:
        conn = mysql.connector.connect(
            host=config["mysql"]["host"],
            user=config["mysql"]["user"],
            password=config["mysql"]["password"],
            database=config["mysql"]["database"]
        )
        return conn
    except mysql.connector.Error as e:
        logging.error(f"Error connecting to MySQL: {e}")
        return None

# def get_checked_commit_hash(conn):
#     try:
#         cursor = conn.cursor(dictionary=True)
#         cursor.execute("SELECT value FROM checked_commit WHERE id = 1")
#         result = cursor.fetchone()
#         return result["value"] if result else ""
#     except Exception as e:
#         logging.error(f"Error fetching checked commit hash: {e}")
#         return ""

# def update_checked_commit_hash(conn, checked_commit_hash):
#     try:
#         cursor = conn.cursor()
#         cursor.execute("UPDATE checked_commit SET value = %s WHERE id = 1", (checked_commit_hash,))
#         conn.commit()
#         logging.info(f"Checked commit updated to {checked_commit_hash}")
#     except Exception as e:
#         logging.error(f"Error updating checked commit hash: {e}")

# Fetch commit details from GitHub API
def get_latest_commits(GITHUB_API_URL):
    response = requests.get(GITHUB_API_URL)
    if response.status_code == 200:
        return response.json()
    else:
        logging.error(f"Error fetching commits from GitHub: {response.status_code}")
        return []

# Extract CVE IDs from commit messages
def extract_cve_ids(commits):
    new_cve_ids = []
    updated_cve_ids = []
    
    # Regex to capture CVE IDs that start with "CVE-" and follow the correct format
    cve_regex = r"CVE-\d+-\d+"
    
    for commit in commits:
        message = commit.get('commit', {}).get('message', '')
        
        # Extract new CVEs
        new_cve_match = re.search(r"\d+\s+new\sCVEs\:\s+CVE(.*?)\n", message)
        if new_cve_match:
            new_cves = re.findall(cve_regex, new_cve_match.group(0))
            new_cve_ids.extend(new_cves)
        
        # Extract updated CVEs
        updated_cve_match = re.search(r"\d+\s+updated\sCVEs\:\s+CVE(.*?)\n", message)
        if updated_cve_match:
            updated_cves = re.findall(cve_regex, updated_cve_match.group(0))
            updated_cve_ids.extend(updated_cves)

    return new_cve_ids, updated_cve_ids

# Construct the CVE URL based on CVE ID format
def construct_cve_url(cve_id, BASE_CVE_URL):
    year = cve_id.split("-")[1]  # Extract year
    cve_number = cve_id.split("-")[2]  # Extract the numerical part of CVE

    # Depending on the length of the numerical part, adjust the "xxx" format
    subfolder = cve_number[0:len(cve_number)-3] + "xxx"
    
    # Construct the full URL
    cve_file_url = f"{BASE_CVE_URL}{year}/{subfolder}/{cve_id}.json"
    return cve_file_url

# Fetch CVE details from GitHub raw file URL
def fetch_cve_details(cve_id, BASE_CVE_URL):
    cve_file_url = construct_cve_url(cve_id, BASE_CVE_URL)
    response = requests.get(cve_file_url)
    if response.status_code == 200:
        return response.json()
    else:
        logging.error(f"Error fetching details for {cve_id}: {response.status_code}")
        return {}

# Alert CVE based on the tech stack and existing CVEs in the database
def alert_cve(config):
    conn = connect_db(config)
    if not conn:
        return

    # Get URLs from config
    GITHUB_API_URL = config["github"]["api-url"]
    BASE_CVE_URL = config["github"]["raw-url"]

    # Fetch new and updated CVEs
    commits = get_latest_commits(GITHUB_API_URL)
    if not commits:
        return

    new_cve_ids, updated_cve_ids = extract_cve_ids(commits)

    # Process new CVEs
    if not new_cve_ids:
        return

    try:
        cursor = conn.cursor(dictionary=True)
        cursor.execute("SELECT cve_id FROM saved_cve")
        existing_cve_ids = [row["cve_id"] for row in cursor.fetchall()]

        cursor.execute("SELECT tech FROM techstack")
        techstack = [row["tech"].strip().lower() for row in cursor.fetchall()]

        for tech in techstack:
            for cve_id in new_cve_ids:
                try:
                    cve_data = fetch_cve_details(cve_id, BASE_CVE_URL)
                    cve_summary = cve_data.get("containers", {}).get("cna", {}).get("descriptions", [{}])[0].get("value", "").lower()

                    # Check if the tech is mentioned in the CVE summary and the CVE is not already saved
                    if tech in cve_summary and cve_id not in existing_cve_ids:
                        cve_data["tech"] = tech
                        if chat.send_cve_to_chat(cve_data):  # Send alert to chat
                            cursor.execute("INSERT INTO saved_cve (cve_id) VALUES (%s)", (cve_id,))
                            conn.commit()
                            logging.info(f"Alerted and saved CVE {cve_id}")
                            # Add CVE to existing_cve_ids list to prevent duplicate alerts in the current run
                            existing_cve_ids.append(cve_id)
                except Exception as e:
                    logging.error(f"Error processing CVE {cve_id}: {e}")
    except Exception as e:
        logging.error(f"Error in alert_cve function: {e}")
    finally:
        conn.close()

# Main logic
def main():
    logging.info(f"Running schedule script.")
    config = load_config()
    if not config:
        logging.error("Config file not found!")
        return

    alert_cve(config)

if __name__ == "__main__":
    main()